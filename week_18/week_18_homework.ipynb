{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat is a neural network? What are the general steps required to build a neural network? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are computing systems that are inspired by the neural networks in brains. They learn by example and can classify and make predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the steps? \n",
    "\n",
    "Clean the data\n",
    "\n",
    "Select the architecture\n",
    "\n",
    "train the neural network\n",
    "\n",
    "tweak the performance\n",
    "\n",
    "test\n",
    "\n",
    "deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2.\tGenerally, how do you check the performance of a neural network? Why? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a bunch of methods to check the performance \n",
    "\n",
    "# regression\n",
    "\n",
    "MSE\n",
    "\n",
    "NMSE\n",
    "\n",
    "RMSE\n",
    "\n",
    "R Squared\n",
    "\n",
    "# For classification\n",
    "\n",
    "TP rate\n",
    "\n",
    "FP Rate\n",
    "\n",
    "F Measure\n",
    "\n",
    "Acurracy\n",
    "\n",
    "Precision\n",
    "\n",
    "Recall\n",
    "\n",
    "Mean squared error is most common for regression,\n",
    "\n",
    "Why do we want to check the performance? Because having an accurate model is the only reason for making a model. It is pointless to have a model with terrible performance. If you check the performance you can tweak a ton of different options to try to make it perform better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tCreate a neural network using keras to predict the outcome of either of these datasets: \n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone\n",
    "\n",
    "We preprocessed this last week so I saved the final version to use here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  Sex_F  Sex_I  Sex_M  \n",
       "0         0.150     15      0      0      1  \n",
       "1         0.070      7      0      0      1  \n",
       "2         0.210      9      1      0      0  \n",
       "3         0.155     10      0      0      1  \n",
       "4         0.055      7      0      1      0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df  = pd.read_csv(r\"C:\\Users\\weird\\Documents\\Data_Science_CG_2021\\homework\\week_18.csv\")\n",
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = abalone_df.drop(['Rings'], axis=1)\n",
    "y = abalone_df['Rings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= StandardScaler()\n",
    "X=sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 300)               3300      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 274,501\n",
      "Trainable params: 274,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 300)               3300      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 274,501\n",
      "Trainable params: 274,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - 3s 35ms/step - loss: 56.9485 - mae: 6.4893 - root_mean_squared_error: 7.3874 - val_loss: 5.7641 - val_mae: 1.9044 - val_root_mean_squared_error: 2.4009\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 6.3832 - mae: 1.9780 - root_mean_squared_error: 2.5249 - val_loss: 4.7488 - val_mae: 1.5439 - val_root_mean_squared_error: 2.1792\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 5.0576 - mae: 1.6523 - root_mean_squared_error: 2.2475 - val_loss: 4.3195 - val_mae: 1.5680 - val_root_mean_squared_error: 2.0783\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 4.8399 - mae: 1.6537 - root_mean_squared_error: 2.1994 - val_loss: 4.1530 - val_mae: 1.4719 - val_root_mean_squared_error: 2.0379\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 4.2506 - mae: 1.5319 - root_mean_squared_error: 2.0604 - val_loss: 4.0439 - val_mae: 1.5678 - val_root_mean_squared_error: 2.0110\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 4.3390 - mae: 1.5829 - root_mean_squared_error: 2.0826 - val_loss: 3.8063 - val_mae: 1.4304 - val_root_mean_squared_error: 1.9510\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 4.2040 - mae: 1.5200 - root_mean_squared_error: 2.0491 - val_loss: 3.6758 - val_mae: 1.4751 - val_root_mean_squared_error: 1.9172\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 3.6975 - mae: 1.4373 - root_mean_squared_error: 1.9222 - val_loss: 3.5978 - val_mae: 1.4711 - val_root_mean_squared_error: 1.8968\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 3.6127 - mae: 1.4129 - root_mean_squared_error: 1.8999 - val_loss: 3.7482 - val_mae: 1.5268 - val_root_mean_squared_error: 1.9360\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 3.5328 - mae: 1.4030 - root_mean_squared_error: 1.8791 - val_loss: 3.6847 - val_mae: 1.4681 - val_root_mean_squared_error: 1.9196\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 3.5585 - mae: 1.4166 - root_mean_squared_error: 1.8860 - val_loss: 3.5077 - val_mae: 1.4384 - val_root_mean_squared_error: 1.8729\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 3.3549 - mae: 1.3676 - root_mean_squared_error: 1.8308 - val_loss: 3.4286 - val_mae: 1.3591 - val_root_mean_squared_error: 1.8516\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 3.4173 - mae: 1.3477 - root_mean_squared_error: 1.8484 - val_loss: 3.7375 - val_mae: 1.5197 - val_root_mean_squared_error: 1.9333\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 3.6974 - mae: 1.4648 - root_mean_squared_error: 1.9223 - val_loss: 3.4393 - val_mae: 1.4022 - val_root_mean_squared_error: 1.8545\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 3.4168 - mae: 1.3756 - root_mean_squared_error: 1.8483 - val_loss: 3.4989 - val_mae: 1.3467 - val_root_mean_squared_error: 1.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x285b34e3250>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_cols = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.summary()\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience = 3)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# Compile the model\n",
    "#model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mean_squared_error'])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','RootMeanSquaredError'])\n",
    "\n",
    "#model.fit(X_train, y_train,  validation_split = .3, epochs = 30, batch_size=100,verbose=1,callbacks = [early_stopping_monitor])\n",
    "model.fit(X, y, validation_split = .3, epochs = 30, batch_size=100,verbose=1,callbacks = [early_stopping_monitor])                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8705"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "NNRMSE = 1.8705\n",
    "NNRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  Sex_F  Sex_I  Sex_M  \n",
       "0         0.150     15      0      0      1  \n",
       "1         0.070      7      0      0      1  \n",
       "2         0.210      9      1      0      0  \n",
       "3         0.155     10      0      0      1  \n",
       "4         0.055      7      0      1      0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tWrite another algorithm to predict the same result as the previous question using either KNN or logistic regression.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9119603708535091"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "LR = LinearRegression()\n",
    "\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = mse**.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1654728128246297"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression(max_iter = 7500, random_state = 27)\n",
    "LogReg.fit(X_train, y_train)\n",
    "LogRegy_pred = LogReg.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, LogRegy_pred)\n",
    "\n",
    "RMSE = MSE**.5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tCreate a neural network using pytorch to predict the same result as question 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = abalone_df.drop('Rings', axis=1).values\n",
    "y = abalone_df['Rings'].values\n",
    "\n",
    "# Split into training and test set\n",
    "PTX_train, PTX_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=27)\n",
    "\n",
    "# #Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(PTX_train)\n",
    "X_test=sc.fit_transform(PTX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8600, -0.9299, -0.6180,  ..., -0.6738,  1.4274, -0.7476],\n",
      "        [ 0.5688,  0.6483,  0.3110,  ..., -0.6738, -0.7006,  1.3377],\n",
      "        [ 1.5774,  1.6156,  1.7709,  ..., -0.6738, -0.7006,  1.3377],\n",
      "        ...,\n",
      "        [-0.1036, -0.0135, -0.3525,  ..., -0.6738, -0.7006,  1.3377],\n",
      "        [-0.9440, -0.7772, -0.8834,  ..., -0.6738,  1.4274, -0.7476],\n",
      "        [-0.0195, -0.2680, -0.3525,  ..., -0.6738,  1.4274, -0.7476]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #this has activation functions\n",
    "\n",
    "# Creating tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "#based on error messages further down, I think these should be float, but it got \n",
    "#very angry at me when I tried to change them to FloatTensor so we'll just \n",
    "#cast to float later. \n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=10, hidden1=20, hidden2=20, out_features =1):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #apply activation functions\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(27)\n",
    "\n",
    "#instantiate the model\n",
    "model = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_function = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 with loss: 7.701865196228027\n",
      "Epoch number: 11 with loss: 7.699443817138672\n",
      "Epoch number: 21 with loss: 7.6972455978393555\n",
      "Epoch number: 31 with loss: 7.695244789123535\n",
      "Epoch number: 41 with loss: 7.693408012390137\n",
      "Epoch number: 51 with loss: 7.691705703735352\n",
      "Epoch number: 61 with loss: 7.6901421546936035\n",
      "Epoch number: 71 with loss: 7.688711643218994\n",
      "Epoch number: 81 with loss: 7.687398433685303\n",
      "Epoch number: 91 with loss: 7.686204433441162\n",
      "Epoch number: 101 with loss: 7.685123920440674\n",
      "Epoch number: 111 with loss: 7.6841349601745605\n",
      "Epoch number: 121 with loss: 7.6832275390625\n",
      "Epoch number: 131 with loss: 7.682391166687012\n",
      "Epoch number: 141 with loss: 7.681618690490723\n",
      "Epoch number: 151 with loss: 7.680904388427734\n",
      "Epoch number: 161 with loss: 7.68024206161499\n",
      "Epoch number: 171 with loss: 7.679628372192383\n",
      "Epoch number: 181 with loss: 7.679061412811279\n",
      "Epoch number: 191 with loss: 7.678535461425781\n",
      "Epoch number: 201 with loss: 7.678049087524414\n",
      "Epoch number: 211 with loss: 7.677600383758545\n",
      "Epoch number: 221 with loss: 7.677189350128174\n",
      "Epoch number: 231 with loss: 7.6768083572387695\n",
      "Epoch number: 241 with loss: 7.676455497741699\n"
     ]
    }
   ],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 250\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = loss_function(y_pred.float(), y_train.float())\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss.item()}')\n",
    "    \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() #for backward propagation \n",
    "    optimizer.step() #performs one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7706417122648137"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchRMSE = 7.676455497741699**.5\n",
    "torchRMSE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tCompare the performance of the neural networks to the other model you created. Which performed better? Why do you think that is?\n",
    "\n",
    "\n",
    "My Keras model performed the best. My guess is that by design it is better than linear or logistic regression. I think if I had a more solid understanding of what was happening in the pytorch version I might be able to get that down and better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras: 1.8705\n",
      "LogisticRegression: 2.1654728128246297\n",
      "LinearRegression: 1.9119603708535091\n",
      "Pytorch: 2.7706417122648137\n"
     ]
    }
   ],
   "source": [
    "print('Keras: ' + str(NNRMSE))\n",
    "print('LogisticRegression: ' + str(RMSE))\n",
    "print('LinearRegression: ' + str(rmse))\n",
    "print('Pytorch: ' + str(torchRMSE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
