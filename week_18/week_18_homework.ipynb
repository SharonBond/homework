{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat is a neural network? What are the general steps required to build a neural network? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are computing systems that are inspired by the neural networks in brains. They learn by example and can classify and make predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the steps? \n",
    "\n",
    "Clean the data\n",
    "\n",
    "Select the architecture\n",
    "\n",
    "train the neural network\n",
    "\n",
    "tweak the performance\n",
    "\n",
    "test\n",
    "\n",
    "deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2.\tGenerally, how do you check the performance of a neural network? Why? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a bunch of methods to check the performance of regression\n",
    "\n",
    "MSE\n",
    "\n",
    "NMSE\n",
    "\n",
    "RMSE\n",
    "\n",
    "R Squared\n",
    "\n",
    "For classification\n",
    "\n",
    "TP rate\n",
    "\n",
    "FP Rate\n",
    "\n",
    "F Measure\n",
    "\n",
    "Acurracy\n",
    "\n",
    "Precision\n",
    "\n",
    "Recall\n",
    "\n",
    "Mean squared error is most common for regression,\n",
    "\n",
    "Why do we want to check the performance? Because having an accurate model is the only reason for making a model. It is pointless to have a model with terrible performance. If you check the performance you can tweak a ton of different options to try to make it perform better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tCreate a neural network using keras to predict the outcome of either of these datasets: \n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_list = ['Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weight','Rings']\n",
    "abalone_df = pd.read_table(\"abalone.data\",sep=\",\",header=None,names=column_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  Sex_F  Sex_I  Sex_M  \n",
       "0         0.150     15      0      0      1  \n",
       "1         0.070      7      0      0      1  \n",
       "2         0.210      9      1      0      0  \n",
       "3         0.155     10      0      0      1  \n",
       "4         0.055      7      0      1      0  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df = pd.get_dummies(abalone_df)\n",
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_df = abalone_df[abalone_df.Height != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       1\n",
       "2       1\n",
       "3      15\n",
       "4      57\n",
       "5     115\n",
       "6     258\n",
       "7     391\n",
       "8     567\n",
       "9     689\n",
       "10    634\n",
       "11    487\n",
       "12    267\n",
       "13    203\n",
       "14    126\n",
       "15    103\n",
       "16     67\n",
       "17     58\n",
       "18     42\n",
       "19     32\n",
       "20     26\n",
       "21     14\n",
       "22      6\n",
       "23      9\n",
       "24      2\n",
       "25      1\n",
       "26      1\n",
       "27      2\n",
       "29      1\n",
       "Name: Rings, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df['Rings'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4122 entries, 0 to 4176\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Length          4122 non-null   float64\n",
      " 1   Diameter        4122 non-null   float64\n",
      " 2   Height          4122 non-null   float64\n",
      " 3   Whole weight    4122 non-null   float64\n",
      " 4   Shucked weight  4122 non-null   float64\n",
      " 5   Viscera weight  4122 non-null   float64\n",
      " 6   Shell weight    4122 non-null   float64\n",
      " 7   Rings           4122 non-null   int64  \n",
      " 8   Sex_F           4122 non-null   uint8  \n",
      " 9   Sex_I           4122 non-null   uint8  \n",
      " 10  Sex_M           4122 non-null   uint8  \n",
      "dtypes: float64(7), int64(1), uint8(3)\n",
      "memory usage: 301.9 KB\n"
     ]
    }
   ],
   "source": [
    "abalone_df = abalone_df[(abalone_df['Rings'] < 21) & (abalone_df['Rings']>3)]\n",
    "abalone_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length            0.16500\n",
      "Diameter          0.13500\n",
      "Height            0.05000\n",
      "Whole weight      0.70350\n",
      "Shucked weight    0.31575\n",
      "Viscera weight    0.15800\n",
      "Shell weight      0.19225\n",
      "Rings             3.00000\n",
      "Sex_F             1.00000\n",
      "Sex_I             1.00000\n",
      "Sex_M             1.00000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4055, 11)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_abalone=abalone_df.copy()\n",
    "Q1 = out_abalone.quantile(0.25)\n",
    "Q3 = out_abalone.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "abalone_df = out_abalone[~((out_abalone < (Q1 - 2.5 * IQR)) |(out_abalone > (Q3 + 2.5 * IQR))).any(axis=1)]\n",
    "abalone_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = abalone_df.drop(['Rings'], axis=1)\n",
    "y = abalone_df['Rings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57816635, -0.43195836, -1.16192728, ..., -0.66948808,\n",
       "        -0.69510779,  1.31974141],\n",
       "       [-1.46684626, -1.45682005, -1.29490355, ..., -0.66948808,\n",
       "        -0.69510779,  1.31974141],\n",
       "       [ 0.05660501,  0.13171558, -0.09811714, ...,  1.49367858,\n",
       "        -0.69510779, -0.7577242 ],\n",
       "       ...,\n",
       "       [ 0.64905828,  0.69538951,  1.76355062, ..., -0.66948808,\n",
       "        -0.69510779,  1.31974141],\n",
       "       [ 0.86064874,  0.79787568,  0.30081167, ...,  1.49367858,\n",
       "        -0.69510779, -0.7577242 ],\n",
       "       [ 1.58005628,  1.51527887,  1.49759808, ..., -0.66948808,\n",
       "        -0.69510779,  1.31974141]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 300)               3300      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 274,501\n",
      "Trainable params: 274,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 300)               3300      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 274,501\n",
      "Trainable params: 274,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - 3s 40ms/step - loss: 57.5010 - mean_squared_error: 57.5010 - val_loss: 5.2655 - val_mean_squared_error: 5.2655\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 6.0546 - mean_squared_error: 6.0546 - val_loss: 4.5992 - val_mean_squared_error: 4.5992\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 4.9972 - mean_squared_error: 4.9972 - val_loss: 4.2172 - val_mean_squared_error: 4.2172\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 4.8389 - mean_squared_error: 4.8389 - val_loss: 4.0770 - val_mean_squared_error: 4.0770\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 4.2479 - mean_squared_error: 4.2479 - val_loss: 4.0434 - val_mean_squared_error: 4.0434\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 4.1634 - mean_squared_error: 4.1634 - val_loss: 3.9213 - val_mean_squared_error: 3.9213\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 4.0557 - mean_squared_error: 4.0557 - val_loss: 3.6156 - val_mean_squared_error: 3.6156\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 3.7475 - mean_squared_error: 3.7475 - val_loss: 3.5835 - val_mean_squared_error: 3.5835\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 3.7089 - mean_squared_error: 3.7089 - val_loss: 3.6652 - val_mean_squared_error: 3.6652\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 3.5950 - mean_squared_error: 3.5950 - val_loss: 3.7169 - val_mean_squared_error: 3.7169\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 3.7687 - mean_squared_error: 3.7687 - val_loss: 3.4712 - val_mean_squared_error: 3.4712\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 3.3995 - mean_squared_error: 3.3995 - val_loss: 3.4827 - val_mean_squared_error: 3.4827\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 3.4763 - mean_squared_error: 3.4763 - val_loss: 4.2389 - val_mean_squared_error: 4.2389\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 3.8126 - mean_squared_error: 3.8126 - val_loss: 3.3849 - val_mean_squared_error: 3.3849\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 3.4276 - mean_squared_error: 3.4276 - val_loss: 3.4934 - val_mean_squared_error: 3.4934\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 3.3857 - mean_squared_error: 3.3857 - val_loss: 4.0144 - val_mean_squared_error: 4.0144\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 3.7554 - mean_squared_error: 3.7554 - val_loss: 3.4380 - val_mean_squared_error: 3.4380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182d84765e0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Specify the model\n",
    "n_cols = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.summary()\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience = 3)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mean_squared_error'])\n",
    "\n",
    "\n",
    "#model.fit(X_train, y_train,  validation_split = .3, epochs = 30, batch_size=100,verbose=1,callbacks = [early_stopping_monitor])\n",
    "model.fit(X, y, validation_split = .3, epochs = 30, batch_size=100,verbose=1,callbacks = [early_stopping_monitor])\n",
    "\n",
    "                                                                              \n",
    "                                                                              \n",
    "                                                                 \n",
    "                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8541844568434933"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNMSE = 3.4380\n",
    "NNRMSE = NNMSE**.5\n",
    "NNRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  Sex_F  Sex_I  Sex_M  \n",
       "0         0.150     15      0      0      1  \n",
       "1         0.070      7      0      0      1  \n",
       "2         0.210      9      1      0      0  \n",
       "3         0.155     10      0      0      1  \n",
       "4         0.055      7      0      1      0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tWrite another algorithm to predict the same result as the previous question using either KNN or logistic regression.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.908865138210307"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "LR = LinearRegression()\n",
    "\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = mse**.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3526414812280136"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression(max_iter = 7500, random_state = 27)\n",
    "LogReg.fit(X_train, y_train)\n",
    "LogRegy_pred = LogReg.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, LogRegy_pred)\n",
    "\n",
    "RMSE = MSE**.5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tCreate a neural network using pytorch to predict the same result as question 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = abalone_df.drop('Rings', axis=1).values\n",
    "y = abalone_df['Rings'].values\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=27)\n",
    "\n",
    "# #Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(PTX_train)\n",
    "X_test=sc.fit_transform(PTX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8600, -0.9299, -0.6180,  ..., -0.6738,  1.4274, -0.7476],\n",
      "        [ 0.5688,  0.6483,  0.3110,  ..., -0.6738, -0.7006,  1.3377],\n",
      "        [ 1.5774,  1.6156,  1.7709,  ..., -0.6738, -0.7006,  1.3377],\n",
      "        ...,\n",
      "        [-0.1036, -0.0135, -0.3525,  ..., -0.6738, -0.7006,  1.3377],\n",
      "        [-0.9440, -0.7772, -0.8834,  ..., -0.6738,  1.4274, -0.7476],\n",
      "        [-0.0195, -0.2680, -0.3525,  ..., -0.6738,  1.4274, -0.7476]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #this has activation functions\n",
    "\n",
    "# Creating tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "#based on error messages further down, I think these should be float, but it got \n",
    "#very angry at me when I tried to change them to FloatTensor so we'll just \n",
    "#cast to float later. \n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=10, hidden1=20, hidden2=20, out_features =1):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #apply activation functions\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(27)\n",
    "\n",
    "#instantiate the model\n",
    "model = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_function = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 with loss: 7.67382287979126\n",
      "Epoch number: 11 with loss: 7.673658847808838\n",
      "Epoch number: 21 with loss: 7.673503875732422\n",
      "Epoch number: 31 with loss: 7.673357009887695\n",
      "Epoch number: 41 with loss: 7.673215389251709\n",
      "Epoch number: 51 with loss: 7.673080921173096\n",
      "Epoch number: 61 with loss: 7.672955513000488\n",
      "Epoch number: 71 with loss: 7.672837734222412\n",
      "Epoch number: 81 with loss: 7.672726154327393\n",
      "Epoch number: 91 with loss: 7.6726226806640625\n",
      "Epoch number: 101 with loss: 7.672525405883789\n",
      "Epoch number: 111 with loss: 7.672430038452148\n",
      "Epoch number: 121 with loss: 7.672338962554932\n",
      "Epoch number: 131 with loss: 7.672253131866455\n",
      "Epoch number: 141 with loss: 7.672173976898193\n",
      "Epoch number: 151 with loss: 7.672099590301514\n",
      "Epoch number: 161 with loss: 7.6720290184021\n",
      "Epoch number: 171 with loss: 7.671961307525635\n",
      "Epoch number: 181 with loss: 7.671895980834961\n",
      "Epoch number: 191 with loss: 7.671833515167236\n"
     ]
    }
   ],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 200\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = loss_function(y_pred.float(), y_train.float())\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss.item()}')\n",
    "    \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() #for backward propagation \n",
    "    optimizer.step() #performs one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.769807487022742"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchRMSE = 7.671833515167236**.5\n",
    "torchRMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\n\\ny_pred = []\\n\\nwith torch.no_grad():\\n    for i, data in enumerate(X_test):\\n        prediction = model(data)\\n        y_pred.append(prediction.argmax().item())\\n\\n'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        prediction = model(data)\n",
    "        y_pred.append(prediction.argmax().item())\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report\n",
    "\n",
    "#print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tCompare the performance of the neural networks to the other model you created. Which performed better? Why do you think that is?\n",
    "\n",
    "\n",
    "My Keras model performed the best. My guess is that by design it is better than linear or logistic regression. I think if I had a more solid understanding of what was happening in the pytorch version I might be able to get that down and better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras: 1.8541844568434933\n",
      "LogisticRegression: 2.3526414812280136\n",
      "LinearRegression: 1.908865138210307\n",
      "Pytorch: 2.769807487022742\n"
     ]
    }
   ],
   "source": [
    "print('Keras: ' + str(NNRMSE))\n",
    "print('LogisticRegression: ' + str(RMSE))\n",
    "print('LinearRegression: ' + str(rmse))\n",
    "print('Pytorch: ' + str(torchRMSE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
