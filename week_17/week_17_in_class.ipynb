{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Write simple (straightforward) definitions for the following parameters for\n",
    "RandomForestClassifier\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClass\n",
    "ifier.html) and indicate how they correlate with the precision and recall for the basic\n",
    "diabetes model we built in class. You will need to rerun the model multiple times to do\n",
    "so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diabetes_df = pd.read_csv(\"../week_13/diabetes.csv\")\n",
    "diabetes_df.head()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimators - number of trees in forest. Default is 100. Precision and recall seem to rise and fall together. Out of the tested values, 200 was the best and 300 starts to go downhill again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  1\n",
      "0.6623376623376623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       100\n",
      "           1       0.52      0.46      0.49        54\n",
      "\n",
      "    accuracy                           0.66       154\n",
      "   macro avg       0.62      0.62      0.62       154\n",
      "weighted avg       0.65      0.66      0.66       154\n",
      "\n",
      "For  100\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  200\n",
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  300\n",
      "0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.68      0.59      0.63        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.72      0.73       154\n",
      "weighted avg       0.75      0.76      0.76       154\n",
      "\n",
      "For  400\n",
      "0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       100\n",
      "           1       0.65      0.59      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.71      0.72       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = [1, 100, 200, 300, 400]\n",
    "\n",
    "for item in list: \n",
    "    rf = RandomForestClassifier( n_estimators= item, random_state =42)\n",
    "\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"For  \" + str(item))\n",
    "    print(rf.score(X_test, y_test))\n",
    "\n",
    "    print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth is maximum depth of the tree as precision incresases, recall falls (in almost all the cases). Precision increass with max_depth number increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  1\n",
      "0.6818181818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       100\n",
      "           1       0.86      0.11      0.20        54\n",
      "\n",
      "    accuracy                           0.68       154\n",
      "   macro avg       0.77      0.55      0.50       154\n",
      "weighted avg       0.74      0.68      0.59       154\n",
      "\n",
      "For  2\n",
      "0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       100\n",
      "           1       0.73      0.35      0.48        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.73      0.64      0.65       154\n",
      "weighted avg       0.73      0.73      0.70       154\n",
      "\n",
      "For  3\n",
      "0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       100\n",
      "           1       0.67      0.44      0.53        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.66      0.67       154\n",
      "weighted avg       0.72      0.73      0.71       154\n",
      "\n",
      "For  4\n",
      "0.7337662337662337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       100\n",
      "           1       0.66      0.50      0.57        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.68      0.69       154\n",
      "weighted avg       0.73      0.73      0.72       154\n",
      "\n",
      "For  5\n",
      "0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       100\n",
      "           1       0.64      0.50      0.56        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.70      0.68      0.68       154\n",
      "weighted avg       0.72      0.73      0.72       154\n",
      "\n",
      "For  6\n",
      "0.7402597402597403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       100\n",
      "           1       0.65      0.56      0.60        54\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.71      0.70      0.70       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n",
      "For  7\n",
      "0.7402597402597403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       100\n",
      "           1       0.66      0.54      0.59        54\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.72      0.69      0.70       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n",
      "For  8\n",
      "0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       100\n",
      "           1       0.67      0.56      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  9\n",
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  10\n",
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       100\n",
      "           1       0.69      0.61      0.65        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.74      0.73      0.74       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  11\n",
      "0.7792207792207793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       100\n",
      "           1       0.72      0.61      0.66        54\n",
      "\n",
      "    accuracy                           0.78       154\n",
      "   macro avg       0.76      0.74      0.75       154\n",
      "weighted avg       0.77      0.78      0.77       154\n",
      "\n",
      "For  12\n",
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       100\n",
      "           1       0.69      0.61      0.65        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.74      0.73      0.74       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = range(1,13)\n",
    "\n",
    "for item in list: \n",
    "    rf = RandomForestClassifier( n_estimators = 200, max_depth= item, random_state =42)\n",
    "\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"For  \" + str(item))\n",
    "    print(rf.score(X_test, y_test))\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_samples_split the minimum number of samples required to split a node. Default is 2. I struggled to find any real pattern or correlation. Sometimes they went up together, sometimes they didn't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  2\n",
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  3\n",
      "0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       100\n",
      "           1       0.67      0.61      0.64        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.73      0.73       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n",
      "For  4\n",
      "0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.68      0.59      0.63        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.72      0.73       154\n",
      "weighted avg       0.75      0.76      0.76       154\n",
      "\n",
      "For  5\n",
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       100\n",
      "           1       0.69      0.61      0.65        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.74      0.73      0.74       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  6\n",
      "0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       100\n",
      "           1       0.67      0.61      0.64        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.73      0.73       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n",
      "For  7\n",
      "0.7727272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.61      0.65        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.74      0.74       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n",
      "For  8\n",
      "0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       100\n",
      "           1       0.69      0.57      0.63        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.72      0.72       154\n",
      "weighted avg       0.75      0.76      0.75       154\n",
      "\n",
      "For  9\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  10\n",
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       100\n",
      "           1       0.70      0.57      0.63        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.72      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = range(2,11)\n",
    "\n",
    "for item in list: \n",
    "    rf = RandomForestClassifier( n_estimators = 200, min_samples_split= item, random_state =42)\n",
    "\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"For  \" + str(item))\n",
    "    print(rf.score(X_test, y_test))\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  25\n",
      "0.7402597402597403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       100\n",
      "           1       0.66      0.54      0.59        54\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.72      0.69      0.70       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n",
      "For  50\n",
      "0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       100\n",
      "           1       0.64      0.50      0.56        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.70      0.68      0.68       154\n",
      "weighted avg       0.72      0.73      0.72       154\n",
      "\n",
      "For  75\n",
      "0.7337662337662337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       100\n",
      "           1       0.66      0.50      0.57        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.68      0.69       154\n",
      "weighted avg       0.73      0.73      0.72       154\n",
      "\n",
      "For  100\n",
      "0.7402597402597403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       100\n",
      "           1       0.68      0.50      0.57        54\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.72      0.69      0.69       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = [25,50,75,100]\n",
    "\n",
    "for item in list: \n",
    "    rf = RandomForestClassifier( n_estimators = 200, min_samples_split= item, random_state =42)\n",
    "\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"For  \" + str(item))\n",
    "    print(rf.score(X_test, y_test))\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_samples_leaf  the number of samples required to be a node. The default is 1. Seems to be losing both precision and accuracy until about 7 and score, precision, and accuracy all go up. Then they roller coaster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  2\n",
      "score 0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  3\n",
      "score 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       100\n",
      "           1       0.67      0.61      0.64        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.73      0.73       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n",
      "For  4\n",
      "score 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.68      0.59      0.63        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.72      0.73       154\n",
      "weighted avg       0.75      0.76      0.76       154\n",
      "\n",
      "For  5\n",
      "score 0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       100\n",
      "           1       0.69      0.61      0.65        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.74      0.73      0.74       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  6\n",
      "score 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       100\n",
      "           1       0.67      0.61      0.64        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.73      0.73       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n",
      "For  7\n",
      "score 0.7727272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.61      0.65        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.74      0.74       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n",
      "For  8\n",
      "score 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       100\n",
      "           1       0.69      0.57      0.63        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.72      0.72       154\n",
      "weighted avg       0.75      0.76      0.75       154\n",
      "\n",
      "For  9\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  10\n",
      "score 0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       100\n",
      "           1       0.70      0.57      0.63        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.72      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  11\n",
      "score 0.7727272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       100\n",
      "           1       0.72      0.57      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.76      0.73      0.74       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n",
      "For  12\n",
      "score 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       100\n",
      "           1       0.70      0.56      0.62        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.71      0.72       154\n",
      "weighted avg       0.75      0.76      0.75       154\n",
      "\n",
      "For  13\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       100\n",
      "           1       0.68      0.56      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  14\n",
      "score 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.68      0.59      0.63        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.72      0.73       154\n",
      "weighted avg       0.75      0.76      0.76       154\n",
      "\n",
      "For  15\n",
      "score 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       100\n",
      "           1       0.69      0.57      0.63        54\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.72      0.72       154\n",
      "weighted avg       0.75      0.76      0.75       154\n",
      "\n",
      "For  16\n",
      "score 0.7402597402597403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       100\n",
      "           1       0.65      0.56      0.60        54\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.71      0.70      0.70       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n",
      "For  17\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.82       100\n",
      "           1       0.67      0.54      0.60        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  18\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.82       100\n",
      "           1       0.67      0.54      0.60        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  19\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       100\n",
      "           1       0.67      0.56      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  20\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       100\n",
      "           1       0.66      0.57      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.71      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = range(2,21)\n",
    "\n",
    "for item in list: \n",
    "    rf = RandomForestClassifier( n_estimators = 200, min_samples_split= item, random_state =42)\n",
    "\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"For  \" + str(item))\n",
    "    print(\"score \" + str(rf.score(X_test, y_test)))\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_weight_fraction_leaf the minimum weighted fraction of all samples to be in a leaf node. Must be a float between 0.0 and 0.5. As the leaf went up the precision went down and recall went up for the most part. It dragged down accuracy score as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  0\n",
      "score 0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  1e-05\n",
      "score 0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  0.01\n",
      "score 0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       100\n",
      "           1       0.71      0.56      0.63        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.72      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  0.1\n",
      "score 0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81       100\n",
      "           1       0.66      0.46      0.54        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.70      0.67      0.67       154\n",
      "weighted avg       0.72      0.73      0.71       154\n",
      "\n",
      "For  0.2\n",
      "score 0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       100\n",
      "           1       0.70      0.39      0.50        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.72      0.65      0.66       154\n",
      "weighted avg       0.72      0.73      0.70       154\n",
      "\n",
      "For  0.3\n",
      "score 0.7337662337662337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83       100\n",
      "           1       0.84      0.30      0.44        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.78      0.63      0.63       154\n",
      "weighted avg       0.76      0.73      0.69       154\n",
      "\n",
      "For  0.4\n",
      "score 0.6493506493506493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       100\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.32      0.50      0.39       154\n",
      "weighted avg       0.42      0.65      0.51       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  0.5\n",
      "score 0.6493506493506493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       100\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.32      0.50      0.39       154\n",
      "weighted avg       0.42      0.65      0.51       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "list = [0, .00001, .01, .1, .2, .3, .4, .5]\n",
    "\n",
    "for item in list: \n",
    "    rf = RandomForestClassifier( n_estimators = 200, min_weight_fraction_leaf= item, random_state =42)\n",
    "\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"For  \" + str(item))\n",
    "    print(\"score \" + str(rf.score(X_test, y_test)))\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_leaf_nodes restricts the number of leaf nodes but grows the best first. Seems like accuracy, recall, and precision all take a hit and it is better going with the default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  7\n",
      "score 0.7337662337662337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       100\n",
      "           1       0.68      0.46      0.55        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.67      0.68       154\n",
      "weighted avg       0.73      0.73      0.72       154\n",
      "\n",
      "For  14\n",
      "score 0.7402597402597403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81       100\n",
      "           1       0.67      0.52      0.58        54\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.72      0.69      0.70       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n",
      "For  21\n",
      "score 0.7337662337662337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       100\n",
      "           1       0.64      0.54      0.59        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.69      0.69       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "For  28\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       100\n",
      "           1       0.67      0.56      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  35\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  42\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       100\n",
      "           1       0.67      0.56      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  49\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       100\n",
      "           1       0.67      0.56      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  56\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  63\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  70\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  77\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  84\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       100\n",
      "           1       0.66      0.57      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.71      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  91\n",
      "score 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       100\n",
      "           1       0.66      0.57      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.71      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "For  98\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       100\n",
      "           1       0.67      0.59      0.63        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.72      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = range(7, 100, 7)\n",
    "\n",
    "for item in list: \n",
    "    rf = RandomForestClassifier( n_estimators = 200, max_leaf_nodes = item, random_state =42)\n",
    "\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"For  \" + str(item))\n",
    "    print(\"score \" + str(rf.score(X_test, y_test)))\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_impurity_decrease a node splits if the split induces a decrease in impurity greater than or equal to this vale. Default is 0. The higher the number, the lower the precision and score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  0\n",
      "score 0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "For  0.001\n",
      "score 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "For  0.01\n",
      "score 0.7207792207792207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80       100\n",
      "           1       0.66      0.43      0.52        54\n",
      "\n",
      "    accuracy                           0.72       154\n",
      "   macro avg       0.70      0.65      0.66       154\n",
      "weighted avg       0.71      0.72      0.70       154\n",
      "\n",
      "For  0.025\n",
      "score 0.7207792207792207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.81       100\n",
      "           1       0.74      0.31      0.44        54\n",
      "\n",
      "    accuracy                           0.72       154\n",
      "   macro avg       0.73      0.63      0.63       154\n",
      "weighted avg       0.73      0.72      0.68       154\n",
      "\n",
      "For  0.05\n",
      "score 0.6493506493506493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       100\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.32      0.50      0.39       154\n",
      "weighted avg       0.42      0.65      0.51       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  0.7\n",
      "score 0.6493506493506493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       100\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.32      0.50      0.39       154\n",
      "weighted avg       0.42      0.65      0.51       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\weird\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "list = [0,.001, .01, .025, .05, .7]\n",
    "\n",
    "for item in list: \n",
    "    rf = RandomForestClassifier( n_estimators = 200, min_impurity_decrease = item, random_state =42)\n",
    "\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"For  \" + str(item))\n",
    "    print(\"score \" + str(rf.score(X_test, y_test)))\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_impurity_split - deprecated and we shouldn't use it so I'm not going to run it through tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does setting bootstrap=False influence the model performance? Note: the default is\n",
    "bootstrap=True. Explain why your results might be so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The performance is worse. Accuracy, precision, and recall all fall. Setting to false means that it isn't resampling which is something that is done to improve performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier( n_estimators= 200,  random_state =42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print(rf.score(X_test, y_test))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       100\n",
      "           1       0.67      0.59      0.63        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.72      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier( n_estimators= 200, bootstrap=False, random_state =42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print(rf.score(X_test, y_test))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
